{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Restricted Bolzmann machines\n",
    "\n",
    "$\\textbf{v,h}\\in \\{0,1\\}^{m+n}$\n",
    "  \n",
    "&nbsp; $m$ : number of visible node  \n",
    "&nbsp; $n$ : number of hidden nodde  \n",
    "$\\textbf{v}$ : visilbe nodes $(v_1,v_2,\\cdots,v_m)^T$ ($m \\times 1 $ matrix)  \n",
    "$\\textbf{j}$ : hidden nodes $(h_1,h_2,\\cdots,h_n)^T$  ($n \\times 1 $ matrix)\n",
    "    \n",
    "$w_{i,j}, b_j, c_i \\in \\mathbb{R}$   \n",
    "$W : n \\times m $ matrix  \n",
    "$b : m \\times 1 $ matrix  \n",
    "$c : n \\times 1 $ matrix    \n",
    "$$E(\\textbf{v},\\textbf{h})= -\\sum_{i=1}^{n}\\sum_{j=1}^{m}w_{ij}h_iv_j-\\sum_{i=1}^nc_ih_i-\\sum_{j=1}^{m}b_jv_j$$\n",
    "$$\n",
    "= -\\mathbf{w}^TW\\mathbf{v}-c^T\\mathbf{h}-b^T\\mathbf{v}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(\\mathbf{v,h}) = \\frac{e^{-E(\\mathbf{v,h})}}{\\sum_{\\mathbf{v,h}}e^{-E(\\mathbf{v,h})}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood\n",
    "$$\\mathcal{L}(\\theta|v)=p(\\mathbf{v}|\\theta)\n",
    "=\\frac{\\sum_{\\mathbf{h}}e^{-E(\\mathbf{v,h})}}{\\sum_{\\mathbf{v,h}}e^{-E(\\mathbf{v,h})}}$$\n",
    "\n",
    "$$\\ln\\mathcal{L}(\\theta|v)=\\ln p(\\mathbf{v}|\\theta)\n",
    "=\\ln{\\sum_{\\mathbf{h}}e^{-E(\\mathbf{v,h})}}\n",
    "-\\ln{\\sum_{\\mathbf{v,h}}e^{-E(\\mathbf{v,h})}}$$\n",
    "\n",
    "$$\\frac{\\partial\\ln\\mathcal{L}(\\theta|v)}{\\partial \\theta}\n",
    "=\\frac{\\partial}{\\partial \\theta} \\Big{(} \\ln{\\sum_{\\mathbf{h}}e^{-E(\\mathbf{v,h})}} \\Big{)}\n",
    "-\\frac{\\partial}{\\partial \\theta} \\Big{(} \\ln{\\sum_{\\mathbf{v,h}}e^{-E(\\mathbf{v,h})}} \\Big{)}$$\n",
    "\n",
    "$$=-\\frac{1}{\\sum_{\\mathbf{h}}e^{-E(\\mathbf{v,h})}}\n",
    "\\sum_{\\mathbf{h}}e^{-E(\\mathbf{v,h})}\\frac{\\partial E(\\mathbf{v,h})}{\\partial \\theta}\n",
    "+\\frac{1}{\\sum_{\\mathbf{v,h}}e^{-E(\\mathbf{v,h})}}\n",
    "\\sum_{\\mathbf{v,h}}e^{-E(\\mathbf{v,h})}\\frac{\\partial E(\\mathbf{v,h})}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "$$=-\\sum_{\\mathbf{h}}p(\\mathbf{h}|\\mathbf{v})\\frac{\\partial E(\\mathbf{v,h})}{\\partial \\theta}\n",
    "+\n",
    "\\sum_{\\mathbf{v,h}}p(\\mathbf{v},\\mathbf{h})\\frac{\\partial E(\\mathbf{v,h})}{\\partial \\theta}\n",
    "$$\n",
    "### note\n",
    "$$p(\\mathbf{h}|\\mathbf{v})=\\frac{p(\\mathbf{v,h})}{p(\\mathbf{v})}\n",
    "=\\frac{\\frac{1}{Z}e^{-E(\\mathbf{v,h})}}{\\frac{1}{Z}\\sum_{\\mathbf{h}}e^{-E(\\mathbf{v,h})}}\n",
    "(Z \\textsf{ is nomalizing constant})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(\\mathbf{h}|\\mathbf{v})=\\prod_{i=1}^n p(h_i|\\mathbf{v})$$\n",
    "\n",
    "$$p(H_i =1 | \\mathbf{v}) = sigmoid(\\sum_{j=1}^m w_{ij}v_j + c_i)$$\n",
    "$$p(V_j =1 | \\mathbf{h}) = sigmoid(\\sum_{j=1}^n w_{ij}v_j + b_j)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient of Liklihood\n",
    "$\\theta = w_{ij},b_{i},c_{i}$\n",
    "$$\\frac{\\partial\\ln\\mathcal{L}(\\theta|v)}{\\partial w_{ij}}=-\\sum_{\\mathbf{h}}p(\\mathbf{h}|\\mathbf{v})\\frac{\\partial E(\\mathbf{v,h})}{\\partial w_{ij}}\n",
    "+\n",
    "\\sum_{\\mathbf{v,h}}p(\\mathbf{v},\\mathbf{h})\\frac{\\partial E(\\mathbf{v,h})}{\\partial w_{ij}}\n",
    "$$\n",
    "\n",
    "$$=\\sum_{\\mathbf{h}}p(\\mathbf{h}|\\mathbf{v})h_iv_j\n",
    "+\\sum_{\\mathbf{v,h}}p(\\mathbf{v},\\mathbf{h})h_iv_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, data_num = 2, m=10, n=5, k = 100, learning_rate = 1):\n",
    "        '''\n",
    "            m : number of visible nodes\n",
    "            n : number of hidden nodes\n",
    "        '''\n",
    "        self.visible_node = m\n",
    "        self.hidden_node = n\n",
    "        self.k = k\n",
    "        self.data_num = data_num\n",
    "        self.learning_rate= learning_rate\n",
    "        \n",
    "        self.W = tf.Variable(initialize_variable([self.hidden_node, self.visible_node], Type = 'uniform'), name = 'weights')\n",
    "        self.b = tf.Variable(initialize_variable([self.visible_node], Type = 'uniform'), name = 'visible_biases')\n",
    "        self.c = tf.Variable(initialize_variable([self.hidden_node], Type = 'uniform'), name = 'hidden_biases')\n",
    "        \n",
    "        self.visible = tf.placeholder(tf.float32, [self.data_num, self.visible_node])\n",
    "        visible = iteration(self.visible, weights= self.W, hidden_biases=self.c, visible_biases=self.b, k=self.k)\n",
    "\n",
    "        \n",
    "        self.grad_W = tf.matmul(tf.transpose(linear(self.visible, weights = tf.transpose(self.W, [1,0]), biases = self.c), [1,0])\n",
    "                                ,self.visible)-\\\n",
    "                    tf.matmul(tf.transpose(linear(visible, weights = tf.transpose(self.W, [1,0]), biases = self.c), [1,0])\n",
    "                                ,visible)\n",
    "        self.grad_b = tf.reduce_sum(self.visible-visible,[0])\n",
    "        self.grad_c = tf.reduce_sum(linear(self.visible, weights = tf.transpose(self.W, [1,0]), biases = self.c)\n",
    "                        -linear(visible, weights = tf.transpose(self.W, [1,0]), biases = self.c),[0])\n",
    "        print(self.grad_W)\n",
    "        print(self.grad_c)\n",
    "        print(self.grad_b)\n",
    "        self.update_W = tf.assign(self.W, self.W + learning_rate*self.grad_W)\n",
    "        self.update_b = tf.assign(self.b, self.b + learning_rate*self.grad_b)\n",
    "        self.update_c = tf.assign(self.c, self.c + learning_rate*self.grad_c)\n",
    "        self.update = [self.update_W, self.update_b, self.update_c]\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def visible_to_hidden(self, visible):\n",
    "        return self.sess.run(tf.floor(linear(visible, weights = tf.transpose(self.W, [1,0]), biases = self.c)+0.5))    \n",
    "    \n",
    "    def train(self, train_data, train_steps = 100):\n",
    "        self.sess.run(self.update, feed_dict = {self.visible : train_data})\n",
    "\n",
    "    def print_tensors(self):\n",
    "        print_tensor(self.sess, self.W)\n",
    "        print_tensor(self.sess, self.b)\n",
    "        print_tensor(self.sess, self.c)\n",
    "    \n",
    "    def get_free_energy(self, v, h):\n",
    "        '''\n",
    "            input\n",
    "                v : 1D tensor m\n",
    "                h : 1D tensor n\n",
    "            return\n",
    "                free energy\n",
    "        '''\n",
    "        if h.get_shape().ndims!=1 or v.get_shape().ndims!=1:\n",
    "            raise ValueError(\"Dimension should be 1 but dimension h : {} and v : {}\"\n",
    "                                .format(h.get_shape().ndims, v.get_shape().ndims))\n",
    "            \n",
    "        if h.get_shape()[0]!=self.W.get_shape()[0] or v.get_shape()[0]!=self.W.get_shape()[1]:\n",
    "            raise ValueError(\"Size note matches with variables\")\n",
    "        \n",
    "        E1 = tf.matmul(tf.reshape(h, [1, -1]),self.W)\n",
    "        E1 = tf.matmul(E1,tf.reshape(v, [-1, 1]))\n",
    "        E1 = tf.reshape(E1, [1])\n",
    "        E2 = tf.reshape(tf.matmul(tf.reshape(self.b, [1, -1]), tf.reshape(v,[-1, 1])), [1])\n",
    "        E3 = tf.reshape(tf.matmul(tf.reshape(self.c, [1, -1]), tf.reshape(h,[-1, 1])), [1])\n",
    "        energy = -E1-E2-E3\n",
    "        print_tensor(self.sess, -E1-E2-E3)\n",
    "        return energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sub_200:0\", shape=(2, 3), dtype=float32)\n",
      "Tensor(\"Sum_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"Sum:0\", shape=(3,), dtype=float32)\n",
      "weights:0\n",
      "(2, 3)\n",
      "[[-0.16224408  0.65379262  0.49336648]\n",
      " [-0.88399434  0.72778988  0.14434838]]\n",
      "visible_biases:0\n",
      "(3,)\n",
      "[-0.14806104 -0.14889407 -0.93704939]\n",
      "hidden_biases:0\n",
      "(2,)\n",
      "[-0.58097386 -0.61491609]\n",
      "weights:0\n",
      "(2, 3)\n",
      "[[ 0.27561599  1.1719892   0.93122655]\n",
      " [-0.67886877  1.25597835  0.34947392]]\n",
      "visible_biases:0\n",
      "(3,)\n",
      "[ 0.85193896  0.85110593  0.06295061]\n",
      "hidden_biases:0\n",
      "(2,)\n",
      "[-0.34233421 -0.58347917]\n",
      "[[ 1.  0.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "r = RBM(data_num =  2, m = 3, n = 2)\n",
    "r.print_tensors()\n",
    "a = [[1,0,1],[0,1,0]]\n",
    "a = np.array(a,dtype = np.float32)\n",
    "r.train(a, train_steps= 10000000)\n",
    "r.print_tensors()\n",
    "print(r.visible_to_hidden(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
