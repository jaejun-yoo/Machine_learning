{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy\n",
    "from Boltzman, Shannon \n",
    "\n",
    "'Caller + Noise channel => Reciever'  \n",
    "Concept of node or graph starts from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise = $\\frac{1}{p(x)}$  \n",
    "$$ \\texttt{Entropy} = E[\\log(\\textrm{surprise})] = \\sum p(x) \\log \\frac{1}{p(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amout of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H_P(X)= -\\sum_x p(x)\\log p(x)$$\n",
    "\n",
    "$$\\texttt{Joint probability : }H_P(X,Y) = -\\sum_{X,Y} p(x,y)\\log p(s,y)$$\n",
    "$$\\texttt{Conditional probability : }H_P(X|Y) = -\\sum_{X,Y} p(x,y)\\log p(x|y)$$\n",
    "\n",
    "$$H_P(X,Y) = -\\sum_{X,Y} p(x,y) \\log p(x,y) = -\\sum_{X,Y} p(x,y) \\log p(y|x) + p(x,y) \\log p(x)$$\n",
    "$$= -\\sum_{X,Y} p(x,y) \\log p(y|x) - \\sum_{X,Y}p(x,y) \\log p(x)$$\n",
    "$$=H_P(Y|X)-\\sum_{X} p(x)\\log p(x)= H_P(Y|X)+H_P(X)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullback leibler\n",
    "$$D(p(x)||q(x)) = \\sum_{X} p(x) \\log \\frac{p(x)}{q(x)}$$\n",
    "$$ = \\sum_{X} -p(x) \\log \\frac{q(x)}{p(x)}$$\n",
    "$$ = \\sum_{X} -p(x) \\log q(x) +\\sum_{X}p(x)\\log p(x)$$\n",
    "$$ = H_{P,Q}(X)  -H_P(X)$$\n",
    "$ H_{P,Q}(X) $ is a cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X$ : set  \n",
    "$2^X$ : power set of $X$  \n",
    "$\\Sigma \\subset 2^X $\n",
    "closed in etc.  \n",
    "Def of probability$ A \\supset B \\Rightarrow P(A) \\geq P(B), and \\sum P = 1, P(\\emptyset) =0$\n",
    "\n",
    "### Measure\n",
    "$X$ : set  \n",
    "$\\Sigma $ : $\\sigma$ algebra of $X$  \n",
    "$$\\mu(\\emptyset) = 0, \\mu(\\bigcup_{k=1}^{\\infty} E_k) = \\sum_{k=1}^{\\infty} \\mu(E_k)$$\n",
    "\n",
    "probability function is one of the function defined in the measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information\n",
    "$$H(X,Y) - H(Y|X) - H(X|Y) = I(X,Y)$$\n",
    "$$I(X,Y) = \\sum_{X,Y} p(x,y)\\log\\frac{p(x,y)}{p(x)p(y)}$$\n",
    "$$= \\sum_{X,Y} p(x,y)\\log\\frac{p(x,y)}{p(y)}-\\sum_{X,Y} p(x,y)\\log p(x)$$\n",
    "$$=\\sum_{X,Y} p(x,y)\\log p(x|y) +H(X) $$\n",
    "$$=H(X) - H(X|Y) = H(Y)- H(Y|X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$D\\Big{(}p(x,y)||q(x,y)\\big{(}=p(x)p(y)\\big{)}\\Big{)} = \\sum_{X,Y} p(x,y) \\log \\frac{p(x,y)}{p(x)p(y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum liklihood\n",
    "$\\{x_i\\} \\hspace{0.2cm}(i = 1,\\cdots,n )$\n",
    "$$\\textrm{Liklihood} = \\prod_{i=1}^n q(x_i) (q \\in Q) $$\n",
    "     *Maximize*\n",
    "$$\\log \\prod_{i=1}^n q(x_i) = \\sum_{i=1}^n \\log q(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E_p[-log q(x_i)]= -\\sum_{X} p(x)\\log q(x)=\\sum_{X} p(x)\\log \\frac{1}{q(x)}$$\n",
    "Cross-entropy true risk of q(x)\n",
    "$$= \\sum_{X} p(x)\\log \\frac{p(x)}{q(x)} - \\sum_X p(x)\\log p(x)$$\n",
    "$$= D(p||q) + H_p(X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Q = \\{ q| q(x) = \\frac{\\sum_{i=1}^n \\lambda_i f_i(x)}{Z}\\}$$\n",
    "($Z$ : normalizing constant)\n",
    "\n",
    "$E_p(f_j)= \\hat{E}_q(f_j) $\n",
    "\n",
    "MLE, maxmium entroy duality \n",
    "\n",
    "maximum entropy\n",
    "$\\max H(P)$ s.t. $E_p[f_i] = \\hat{E}[f_i]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "$$P(Y|X) = \\frac{P(X,Y)}{P(X)} = \\frac{1}{Z} P(X, Y)$$\n",
    "$$P(X,Y) = \\prod_{i=1}^n P(X_i|X_1,\\cdot, X_{i-1}, Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM(hidden markov model)\n",
    "$$P(Y,x) = \\prod_{i=1}^n P(Y_i)P(X_i|Y_i)$$\n",
    "$$\\Rightarrow P(Y_0)\\prod_{i=1}^n P(Y_i|Y_{i-1})P(X_i|Y_i)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum entropy model\n",
    "Markov model  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF\n",
    "conditional random field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
